{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Pre-Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/founder_V0.3_founder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_News_Articles'] = df['Number_of_News_Articles']/df['Number_of_News_Articles'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Founded_Organizations'] = df['Number_of_Founded_Organizations']/df['Number_of_Founded_Organizations'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Portfolio_Companies'] = df['Number_of_Portfolio_Companies']/df['Number_of_Portfolio_Companies'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Investments_x'] = df['Number_of_Investments_x'] / df['Number_of_Investments_x'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Partner_Investments'] = df['Number_of_Partner_Investments'] /df['Number_of_Partner_Investments'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Lead_Investments_x'] = df['Number_of_Lead_Investments_x']/ df['Number_of_Lead_Investments_x'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Exits_x'] = df['Number_of_Exits_x'] / df['Number_of_Exits_x'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Events_x'] = df['Number_of_Events_x']/ df['Number_of_Events_x'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHE Headquarters & Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_Dummies = pd.get_dummies(df['Headquarters_Location_'])\n",
    "df = pd.concat([df, country_Dummies], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_vals(column_name):\n",
    "    unique_arr = []\n",
    "    for val in df[column_name].values:\n",
    "        arr = val.split(',')\n",
    "        for category in arr:\n",
    "            if category not in unique_arr:\n",
    "                unique_arr.append(category.strip())\n",
    "    return unique_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_vals(column_name):\n",
    "    categories_arr = []\n",
    "    for val in df[column_name].values:\n",
    "        arr = val.split(',')\n",
    "#         for category in arr:\n",
    "        categories_arr.append(arr[0].strip())\n",
    "    return categories_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_arr(array_to_sort):\n",
    "    sorted_arr = sorted(array_to_sort)\n",
    "    return sorted_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count_df = pd.Series(get_all_vals('Categories'))\n",
    "category_count_df = category_count_df.value_counts() # count of category value counts\n",
    "category_df = get_all_vals('Categories') # df of all category values \n",
    "unique_category_df = get_unique_vals('Categories')\n",
    "\n",
    "cat_and_count_df = dict(zip(unique_category_df, category_count_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_df = category_df.insert('Category_Count', cat_and_count_df.get(int(\"{}\".format(category_count_df[]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts() # 131 people responded 2\n",
    "index_names = df[df[\"Gender\"] == 2].index\n",
    "df.drop(index_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(df)\n",
    "clean_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.drop(['Primary_Job_Title', 'Operating_Status', 'Company_Type', 'Success'], axis = 1)\n",
    "y = clean_df['Success'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 1234)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(n_estimators= 1000, objective='binary:logistic', booster='gbtree', learning_rate=.3, colsample_bytree=.3, reg_alpha= .3, random_state = 1234)\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "xgb_y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "xgb_train_score = round(xgb_classifier.score(x_train, y_train)*100, 3)\n",
    "xgb_test_score = round(xgb_classifier.score(x_test, y_test)*100, 3)\n",
    "\n",
    "print(\"Train Accuracy: \" + str(xgb_train_score))\n",
    "print(\"Test Accuracy: \" + str(xgb_test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_classifier)\n",
    "plt.rcParams['figure.figsize'] = [50, 40]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, xgb_y_pred))\n",
    "\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "print(\"MSE: \" + str(mean_squared_error(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors= 10, algorithm= 'auto', n_jobs=-1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "knn_y_pred = knn.predict(x_test)\n",
    "\n",
    "knn_train_score = round(knn.score(x_train, y_train)*100, 2)\n",
    "knn_test_score = round(knn.score(x_test, y_test)*100, 2)\n",
    "\n",
    "print(knn_train_score)\n",
    "print(knn_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "k_neighbor = list(range(1, 50, 2))\n",
    "\n",
    "cross_val_scores = []\n",
    "\n",
    "for k in k_neighbor:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "    cross_val_scores.append(scores.mean())\n",
    "print(cross_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_error = [1 - score for score in cross_val_scores]\n",
    "\n",
    "best_k = k_neighbor[misclassification_error.index(min(misclassification_error))]\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_neighbor, misclassification_error)\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Misclassification Effor\")\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classification = RandomForestClassifier(n_estimators=int(np.sqrt(len(X.columns))))\n",
    "\n",
    "rf_classification.fit(x_train, y_train)\n",
    "\n",
    "rf_y_pred = rf_classification.predict(x_test)\n",
    "\n",
    "rf_score_TEST = round(rf_classification.score(x_test, y_test)*100, 2)\n",
    "rf_score_TRAIN = round(rf_classification.score(x_train, y_train)*100, 2)\n",
    "\n",
    "print(\"Score on Training Data: \" + str(rf_score_TRAIN))\n",
    "print(\"Score on Testing Data: \" + str(rf_score_TEST))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(x_train, y_train)\n",
    "\n",
    "gnb_y_pred = gnb_clf.predict(x_test)\n",
    "\n",
    "gnb_score_TRAIN = round(gnb_clf.score(x_train, y_train)*100, 2)\n",
    "gnb_score_TEST = round(gnb_clf.score(x_test, y_test)*100, 2)\n",
    "\n",
    "print(\"{} Score on Training Data: \".format(str(gnb_clf.__class__.__name__)) + str(gnb_score_TRAIN))\n",
    "print(\"{} Score on Testing Data: \".format(str(gnb_clf.__class__.__name__)) + str(gnb_score_TEST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "dt_clf.fit(x_train, y_train)\n",
    "\n",
    "dt_y_pred = dt_clf.predict(x_test)\n",
    "\n",
    "dt_score_TRAIN = round(dt_clf.score(x_train, y_train)*100, 2)\n",
    "dt_score_TEST = round(dt_clf.score(x_test, y_test)*100, 2)\n",
    "\n",
    "print(\"{} TRAINING Score: \".format(str(dt_clf.__class__.__name__)) + str(dt_score_TRAIN))\n",
    "print(\"{} TESTING Score: \".format(str(dt_clf.__class__.__name__)) + str(dt_score_TEST))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "\n",
    "log_clf.fit(x_train, y_train)\n",
    "\n",
    "log_y_pred = log_clf.predict(x_test)\n",
    "\n",
    "log_score_TRAIN = round(log_clf.score(x_train, y_train)*100, 2)\n",
    "log_score_TEST = round(log_clf.score(x_test, y_test)*100, 2)\n",
    "\n",
    "print(\"{} TRAINING Score: \".format(str(log_clf.__class__.__name__)) + str(log_score_TRAIN))\n",
    "print(\"{} TESTING Score: \".format(str(log_clf.__class__.__name__)) + str(log_score_TEST))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "# dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators= [('rf', rf_clf), ('knn', knn_clf), ('xgb', xgb_clf)],\n",
    "    voting='soft' # more weight to highly confident votes\n",
    ")\n",
    "\n",
    "# voting_clf.fit(x_train, y_train)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "for classifier in (rf_clf, knn_clf, xgb_clf, voting_clf):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(classifier.__class__.__name__)\n",
    "    print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))\n",
    "    print(\"RMSE: \" + str(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "    print(\"MSE: \" + str(mean_squared_error(y_test, y_pred)))\n",
    "    print('\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix & AUC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
